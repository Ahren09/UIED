{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_label(bboxes, d_height, gt_height, bias=0):\n",
    "    bboxes_new = []\n",
    "    scale = gt_height/d_height\n",
    "    for bbox in bboxes:\n",
    "        bbox = [int(b * scale + bias) for b in bbox]\n",
    "        bboxes_new.append(bbox)\n",
    "    return bboxes_new\n",
    "\n",
    "\n",
    "def draw_bounding_box(org, corners, color=(0, 255, 0), line=2, show=False):\n",
    "    board = org.copy()\n",
    "    for i in range(len(corners)):\n",
    "        board = cv2.rectangle(board, (corners[i][0], corners[i][1]), (corners[i][2], corners[i][3]), color, line)\n",
    "    if show:\n",
    "        cv2.imshow('a', cv2.resize(board, (300, 600)))\n",
    "        cv2.waitKey(0)\n",
    "    return board\n",
    "\n",
    "\n",
    "def load_detect_result_txt(reslut_file_root):\n",
    "    def is_bottom_or_top(corner):\n",
    "        column_min, row_min, column_max, row_max = corner\n",
    "        if row_max < 36 or row_min > 725:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    result_files = glob(pjoin(reslut_file_root, '*.txt'))\n",
    "\n",
    "    compos_reform = {}\n",
    "    print('Loading %d detection results' % len(result_files))\n",
    "    for reslut_file in tqdm(result_files):\n",
    "        file = open(reslut_file, 'r')\n",
    "        for compos in file.readlines():\n",
    "            img_name = compos.split()[0]\n",
    "            compos = compos.split()[1:]\n",
    "            for compo in compos:\n",
    "                class_name = compo.split(',')[-1]\n",
    "                compo = [int(c) for c in compo.split(',')[:-1]]\n",
    "\n",
    "                if is_bottom_or_top(compo) or class_name == '4':\n",
    "                   continue\n",
    "\n",
    "                if img_name not in compos_reform:\n",
    "                    compos_reform[img_name] = {'bboxes': [compo], 'categories': [class_name]}\n",
    "                else:\n",
    "                    compos_reform[img_name]['bboxes'].append(compo)\n",
    "                    compos_reform[img_name]['categories'].append(class_name)\n",
    "    return compos_reform\n",
    "\n",
    "\n",
    "def load_ground_truth_json(gt_file):\n",
    "    def get_img_by_id(img_id):\n",
    "        for image in images:\n",
    "            if image['id'] == img_id:\n",
    "                return image['file_name'].split('/')[-1][:-4], (image['height'], image['width'])\n",
    "\n",
    "    def cvt_bbox(bbox):\n",
    "        '''\n",
    "        :param bbox: [x,y,width,height]\n",
    "        :return: [col_min, row_min, col_max, row_max]\n",
    "        '''\n",
    "        bbox = [int(b) for b in bbox]\n",
    "        return [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "\n",
    "    data = json.load(open(gt_file, 'r'))\n",
    "    images = data['images']\n",
    "    annots = data['annotations']\n",
    "    compos = {}\n",
    "    print('Loading %d ground truth' % len(annots))\n",
    "    for annot in tqdm(annots):\n",
    "        img_name, size = get_img_by_id(annot['image_id'])\n",
    "        if img_name not in compos:\n",
    "            compos[img_name] = {'bboxes': [cvt_bbox(annot['bbox'])], 'categories': [annot['category_id']], 'size':size}\n",
    "        else:\n",
    "            compos[img_name]['bboxes'].append(cvt_bbox(annot['bbox']))\n",
    "            compos[img_name]['categories'].append(annot['category_id'])\n",
    "    return compos\n",
    "\n",
    "\n",
    "def eval(detection, ground_truth, img_root, show=True):\n",
    "    def match(org, d_bbox, gt_bboxes, matched):\n",
    "        '''\n",
    "        :param matched: mark if the ground truth component is matched\n",
    "        :param d_bbox: [col_min, row_min, col_max, row_max]\n",
    "        :param gt_bboxes: list of ground truth [[col_min, row_min, col_max, row_max]]\n",
    "        :return: Boolean: if IOU large enough or detected box is contained by ground truth\n",
    "        '''\n",
    "        area_d = (d_bbox[2] - d_bbox[0]) * (d_bbox[3] - d_bbox[1])\n",
    "        for i, gt_bbox in enumerate(gt_bboxes):\n",
    "            if matched[i] == 0:\n",
    "                continue\n",
    "            area_gt = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
    "            col_min = max(d_bbox[0], gt_bbox[0])\n",
    "            row_min = max(d_bbox[1], gt_bbox[1])\n",
    "            col_max = min(d_bbox[2], gt_bbox[2])\n",
    "            row_max = min(d_bbox[3], gt_bbox[3])\n",
    "            # if not intersected, area intersection should be 0\n",
    "            w = max(0, col_max - col_min)\n",
    "            h = max(0, row_max - row_min)\n",
    "            area_inter = w * h\n",
    "            if area_inter == 0:\n",
    "                continue\n",
    "            iod = area_inter / area_d\n",
    "            iou = area_inter / (area_d + area_gt - area_inter)\n",
    "\n",
    "            # if show:\n",
    "            #     print(\"IoDetection: %.3f, IoU: %.3f\" % (iod, iou))\n",
    "            #     broad = draw_bounding_box(org, [d_bbox], color=(0, 0, 255))\n",
    "            #     draw_bounding_box(broad, [gt_bbox], color=(0, 255, 0), show=True)\n",
    "\n",
    "            if iou > 0.5 or iod == 1:\n",
    "                matched[i] = 0\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    amount = len(detection)\n",
    "    pres = []\n",
    "    recalls = []\n",
    "    for i, image_id in enumerate(detection):\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "        img = cv2.imread(pjoin(img_root, image_id + '.jpg'))\n",
    "        d_compos = detection[image_id]\n",
    "        gt_compos = ground_truth[image_id]\n",
    "        d_compos['bboxes'] = resize_label(d_compos['bboxes'], 600, gt_compos['size'][0])\n",
    "        matched = np.ones(len(gt_compos['bboxes']), dtype=int)\n",
    "        for d_bbox in d_compos['bboxes']:\n",
    "            if match(img, d_bbox, gt_compos['bboxes'], matched):\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        FN += sum(matched)\n",
    "\n",
    "        precesion = TP / (TP+FP)\n",
    "        recall = TP / (TP+FN)\n",
    "        \n",
    "        pres.append(precesion)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        if show:\n",
    "            print(\"Number of gt boxes: %d, Number of detected boxes: %d\" % (\n",
    "            len(gt_compos['bboxes']), len(d_compos['bboxes'])))\n",
    "            broad = draw_bounding_box(img,  d_compos['bboxes'], color=(0, 0, 255), line=3)\n",
    "            draw_bounding_box(broad, gt_compos['bboxes'], color=(0, 255, 0), show=show, line=2)\n",
    "            print('[%d/%d] TP:%d, FP:%d, FN:%d, Precesion:%.3f, Recall:%.3f' % (i, amount, TP, FP, FN, precesion, recall))\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print('[%d/%d] TP:%d, FP:%d, FN:%d, Precesion:%.3f, Recall:%.3f' % (i, amount, TP, FP, FN, precesion, recall))\n",
    "    \n",
    "    return pres, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 472/4565 [00:00<00:00, 4684.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4565 detection results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4565/4565 [00:01<00:00, 4554.45it/s]\n",
      "  9%|▉         | 7752/87145 [00:00<00:01, 76956.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 87145 ground truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87145/87145 [00:11<00:00, 7470.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/4563] TP:1, FP:9, FN:4, Precesion:0.100, Recall:0.200\n",
      "[200/4563] TP:3, FP:17, FN:4, Precesion:0.150, Recall:0.429\n",
      "[400/4563] TP:3, FP:6, FN:1, Precesion:0.333, Recall:0.750\n",
      "[600/4563] TP:5, FP:33, FN:1, Precesion:0.132, Recall:0.833\n",
      "[800/4563] TP:17, FP:12, FN:12, Precesion:0.586, Recall:0.586\n",
      "[1000/4563] TP:9, FP:11, FN:6, Precesion:0.450, Recall:0.600\n",
      "[1200/4563] TP:11, FP:23, FN:4, Precesion:0.324, Recall:0.733\n",
      "[1400/4563] TP:7, FP:9, FN:4, Precesion:0.438, Recall:0.636\n",
      "[1600/4563] TP:3, FP:16, FN:7, Precesion:0.158, Recall:0.300\n",
      "[1800/4563] TP:9, FP:28, FN:5, Precesion:0.243, Recall:0.643\n",
      "[2000/4563] TP:5, FP:8, FN:2, Precesion:0.385, Recall:0.714\n",
      "[2200/4563] TP:10, FP:16, FN:14, Precesion:0.385, Recall:0.417\n",
      "[2400/4563] TP:9, FP:26, FN:21, Precesion:0.257, Recall:0.300\n",
      "[2600/4563] TP:15, FP:20, FN:10, Precesion:0.429, Recall:0.600\n",
      "[2800/4563] TP:1, FP:18, FN:5, Precesion:0.053, Recall:0.167\n",
      "[3000/4563] TP:3, FP:14, FN:9, Precesion:0.176, Recall:0.250\n",
      "[3200/4563] TP:2, FP:5, FN:8, Precesion:0.286, Recall:0.200\n",
      "[3400/4563] TP:4, FP:17, FN:2, Precesion:0.190, Recall:0.667\n",
      "[3600/4563] TP:28, FP:29, FN:29, Precesion:0.491, Recall:0.491\n",
      "[3800/4563] TP:15, FP:32, FN:13, Precesion:0.319, Recall:0.536\n",
      "[4000/4563] TP:6, FP:21, FN:4, Precesion:0.222, Recall:0.600\n",
      "[4200/4563] TP:7, FP:16, FN:14, Precesion:0.304, Recall:0.333\n",
      "[4400/4563] TP:1, FP:5, FN:3, Precesion:0.167, Recall:0.250\n"
     ]
    }
   ],
   "source": [
    "detect = load_detect_result_txt('E:\\\\Mulong\\\\Result\\\\rico_remaui')\n",
    "gt = load_ground_truth_json('E:/Mulong/Datasets/rico/instances_test_nontext.json')\n",
    "pres, recalls = eval(detect, gt, 'E:\\\\Mulong\\\\Datasets\\\\rico\\\\combined', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\figure.py:448: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()  # 创建画布\n",
    "ax = plt.subplot()  # 创建作图区域\n",
    "ax.boxplot([pres, recalls])\n",
    "ax.set_xticklabels(['precisions', 'recalls'])\n",
    "plt.grid(axis='y')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
